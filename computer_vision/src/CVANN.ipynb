{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CVANN - Computer Vision Artificial Neural Network\n",
    "\n",
    "import os\n",
    "from tqdm import *\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D, Convolution2D\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def progress_bar(max_, bar_width=40):\n",
    "    try:\n",
    "        if not progress_bar.counter:\n",
    "            progress_bar.counter = 0\n",
    "\n",
    "    except AttributeError:\n",
    "        progress_bar.counter = 0\n",
    "\n",
    "    percentage = str(int((progress_bar.counter + 1)/max_*100))\n",
    "    bar = '[' + '-'*(int(bar_width*(progress_bar.counter+1)/max_) - 1) + '>' + \\\n",
    "          '.'*(bar_width - int(bar_width*(progress_bar.counter + 1)/max_)) + ']' + percentage + '%'\n",
    "\n",
    "    progress_bar.counter += 1\n",
    "\n",
    "    if progress_bar.counter == 1:\n",
    "        print(bar, end='', flush=True)\n",
    "    else:\n",
    "        print('\\b' * len(bar) + bar, end='', flush=True)\n",
    "\n",
    "    if progress_bar.counter == max_:\n",
    "        progress_bar.counter = 0\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sep_grayscale_intervals(img, num_intervals=4, output_path=None):\n",
    "\n",
    "    img_array = img_to_array(img)\n",
    "\n",
    "    for img in range(len(img_array)):\n",
    "        for i in range(len(img_array[img])):\n",
    "            for j in range(len(img_array[img][i])):\n",
    "\n",
    "                pixel = img_array[img][i][j]\n",
    "                new_value = pixel\n",
    "\n",
    "                for interval in range(num_intervals):\n",
    "                    interval_max = 255-((256/num_intervals)*interval)\n",
    "                    if pixel < interval_max:\n",
    "                        new_value = interval_max-(256/num_intervals)\n",
    "\n",
    "                img_array[img][i][j] = new_value\n",
    "\n",
    "    if output_path:\n",
    "        img.save(output_path, 'JPEG')\n",
    "\n",
    "    return array_to_img(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(img_dir_name, img_dimensions=(120, 90)):\n",
    "\n",
    "    print('\\nLoading data: \"' + str(img_dir_name) + '\"')\n",
    "\n",
    "    directory = '..' + os.sep + 'resources' + os.sep + str(img_dir_name)\n",
    "    sub_dir_names = [file for file in os.listdir(directory) if not file.startswith('.')]\n",
    "\n",
    "    # calculate the total number of images | initialize the dictionary mapping the names to integers\n",
    "    total_num_images = 0\n",
    "    i = 0\n",
    "    dictionary = {}\n",
    "\n",
    "    for sub_dir in sub_dir_names:\n",
    "        sub_dir_path = directory + os.sep + sub_dir\n",
    "        image_files = [file for file in os.listdir(sub_dir_path) if not file.startswith('.')]\n",
    "        total_num_images += len(image_files)\n",
    "\n",
    "        dictionary[sub_dir] = i\n",
    "        i += 1\n",
    "\n",
    "    print('Loading ' + str(total_num_images) + ' images\\n')\n",
    "\n",
    "    data = []\n",
    "    labels = np.zeros((total_num_images, 1)).astype('int')\n",
    "    i = 0\n",
    "    for sub_dir in sub_dir_names:\n",
    "\n",
    "        label = int(dictionary[sub_dir])  # the 'label' associated to this folder\n",
    "        sub_dir_path = directory + os.sep + sub_dir\n",
    "        img_files = [file for file in os.listdir(sub_dir_path) if not file.startswith('.')]\n",
    "\n",
    "        for file in tqdm(img_files, desc='current directory of images: ' + sub_dir):\n",
    "\n",
    "            file_path = sub_dir_path + os.sep + file\n",
    "            img = load_img(file_path, grayscale=True, target_size=img_dimensions)\n",
    "            # img = sep_grayscale_intervals(img, num_intervals=8)  # testing phase\n",
    "            img_array = img_to_array(img)\n",
    "\n",
    "            labels = np.insert(labels, i, label, axis=0)  # insert the label at position i\n",
    "            labels = np.delete(labels, -1, axis=0)  # remove the one too many element\n",
    "            data.append(img_array)\n",
    "            i += 1\n",
    "\n",
    "    data = np.asarray(data)\n",
    "    data /= 255\n",
    "    nb_classes = len(dictionary)\n",
    "    labels = to_categorical(labels, nb_classes=nb_classes)\n",
    "\n",
    "    return data, labels, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_network(train, validation, nb_epoch=5, batch_size=40, activations=('relu', 'relu', 'softmax'),\n",
    "                   nb_filters=30, img_dimensions=(120, 90), pool_dimensions=(8, 6), conv_dimensions=(12, 9),\n",
    "                   optimizer='rmsprop'):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(nb_filter=nb_filters, nb_row=conv_dimensions[0], nb_col=conv_dimensions[1],\n",
    "                            input_shape=(1, img_dimensions[0], img_dimensions[1]), activation=activations[0]))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=pool_dimensions))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())  # converts our 2D feature maps to 1D feature vectors\n",
    "    model.add(Dense(128, activation=activations[1]))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(len(train[2]), activation=activations[2]))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x=train[0], y=train[1], nb_epoch=nb_epoch, batch_size=batch_size)\n",
    "\n",
    "    print('\\n')\n",
    "    loss, accuracy = model.evaluate(x=validation[0], y=validation[1], batch_size=batch_size, verbose=1)\n",
    "    print('loss: ' + str(round(loss, 4)))\n",
    "    print('accuracy: ' + str(round(accuracy, 4)) + '\\n')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current directory of images: Sample001:   6%|▌         | 3/50 [00:00<00:01, 26.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data: \"OCRANN_train\"\n",
      "Loading 3100 images\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current directory of images: Sample001: 100%|██████████| 50/50 [00:01<00:00, 28.32it/s]\n",
      "current directory of images: Sample002: 100%|██████████| 50/50 [00:01<00:00, 28.19it/s]\n",
      "current directory of images: Sample003: 100%|██████████| 50/50 [00:01<00:00, 27.18it/s]\n",
      "current directory of images: Sample004: 100%|██████████| 50/50 [00:01<00:00, 28.32it/s]\n",
      "current directory of images: Sample005: 100%|██████████| 50/50 [00:01<00:00, 25.36it/s]\n",
      "current directory of images: Sample006: 100%|██████████| 50/50 [00:01<00:00, 25.91it/s]\n",
      "current directory of images: Sample007: 100%|██████████| 50/50 [00:01<00:00, 27.53it/s]\n",
      "current directory of images: Sample008: 100%|██████████| 50/50 [00:01<00:00, 28.60it/s]\n",
      "current directory of images: Sample009: 100%|██████████| 50/50 [00:01<00:00, 28.49it/s]\n",
      "current directory of images: Sample010: 100%|██████████| 50/50 [00:01<00:00, 28.06it/s]\n",
      "current directory of images: Sample011: 100%|██████████| 50/50 [00:01<00:00, 27.63it/s]\n",
      "current directory of images: Sample012: 100%|██████████| 50/50 [00:01<00:00, 27.16it/s]\n",
      "current directory of images: Sample013: 100%|██████████| 50/50 [00:01<00:00, 27.44it/s]\n",
      "current directory of images: Sample014: 100%|██████████| 50/50 [00:02<00:00, 22.90it/s]\n",
      "current directory of images: Sample015: 100%|██████████| 50/50 [00:01<00:00, 27.30it/s]\n",
      "current directory of images: Sample016: 100%|██████████| 50/50 [00:01<00:00, 27.71it/s]\n",
      "current directory of images: Sample017: 100%|██████████| 50/50 [00:01<00:00, 27.59it/s]\n",
      "current directory of images: Sample018: 100%|██████████| 50/50 [00:01<00:00, 28.19it/s]\n",
      "current directory of images: Sample019: 100%|██████████| 50/50 [00:01<00:00, 27.85it/s]\n",
      "current directory of images: Sample020: 100%|██████████| 50/50 [00:01<00:00, 25.85it/s]\n",
      "current directory of images: Sample021: 100%|██████████| 50/50 [00:01<00:00, 27.35it/s]\n",
      "current directory of images: Sample022: 100%|██████████| 50/50 [00:01<00:00, 28.38it/s]\n",
      "current directory of images: Sample023: 100%|██████████| 50/50 [00:01<00:00, 28.26it/s]\n",
      "current directory of images: Sample024: 100%|██████████| 50/50 [00:01<00:00, 28.07it/s]\n",
      "current directory of images: Sample025: 100%|██████████| 50/50 [00:01<00:00, 28.09it/s]\n",
      "current directory of images: Sample026: 100%|██████████| 50/50 [00:01<00:00, 27.47it/s]\n",
      "current directory of images: Sample027: 100%|██████████| 50/50 [00:01<00:00, 28.21it/s]\n",
      "current directory of images: Sample028: 100%|██████████| 50/50 [00:01<00:00, 27.77it/s]\n",
      "current directory of images: Sample029: 100%|██████████| 50/50 [00:01<00:00, 27.56it/s]\n",
      "current directory of images: Sample030: 100%|██████████| 50/50 [00:01<00:00, 27.37it/s]\n",
      "current directory of images: Sample031: 100%|██████████| 50/50 [00:01<00:00, 28.45it/s]\n",
      "current directory of images: Sample032: 100%|██████████| 50/50 [00:01<00:00, 28.44it/s]\n",
      "current directory of images: Sample033: 100%|██████████| 50/50 [00:01<00:00, 27.99it/s]\n",
      "current directory of images: Sample034: 100%|██████████| 50/50 [00:01<00:00, 27.60it/s]\n",
      "current directory of images: Sample035: 100%|██████████| 50/50 [00:02<00:00, 24.45it/s]\n",
      "current directory of images: Sample036: 100%|██████████| 50/50 [00:02<00:00, 20.75it/s]\n",
      "current directory of images: Sample037: 100%|██████████| 50/50 [00:02<00:00, 25.48it/s]\n",
      "current directory of images: Sample038: 100%|██████████| 50/50 [00:01<00:00, 27.36it/s]\n",
      "current directory of images: Sample039: 100%|██████████| 50/50 [00:01<00:00, 27.79it/s]\n",
      "current directory of images: Sample040: 100%|██████████| 50/50 [00:01<00:00, 27.57it/s]\n",
      "current directory of images: Sample041: 100%|██████████| 50/50 [00:01<00:00, 27.65it/s]\n",
      "current directory of images: Sample042: 100%|██████████| 50/50 [00:01<00:00, 27.70it/s]\n",
      "current directory of images: Sample043: 100%|██████████| 50/50 [00:01<00:00, 27.83it/s]\n",
      "current directory of images: Sample044: 100%|██████████| 50/50 [00:01<00:00, 28.03it/s]\n",
      "current directory of images: Sample045: 100%|██████████| 50/50 [00:01<00:00, 27.94it/s]\n",
      "current directory of images: Sample046: 100%|██████████| 50/50 [00:01<00:00, 27.98it/s]\n",
      "current directory of images: Sample047: 100%|██████████| 50/50 [00:01<00:00, 27.50it/s]\n",
      "current directory of images: Sample048: 100%|██████████| 50/50 [00:01<00:00, 28.17it/s]\n",
      "current directory of images: Sample049: 100%|██████████| 50/50 [00:01<00:00, 28.15it/s]\n",
      "current directory of images: Sample050: 100%|██████████| 50/50 [00:01<00:00, 28.02it/s]\n",
      "current directory of images: Sample051: 100%|██████████| 50/50 [00:01<00:00, 27.70it/s]\n",
      "current directory of images: Sample052: 100%|██████████| 50/50 [00:02<00:00, 17.66it/s]\n",
      "current directory of images: Sample053: 100%|██████████| 50/50 [00:02<00:00, 19.83it/s]\n",
      "current directory of images: Sample054: 100%|██████████| 50/50 [00:02<00:00, 22.64it/s]\n",
      "current directory of images: Sample055: 100%|██████████| 50/50 [00:01<00:00, 25.64it/s]\n",
      "current directory of images: Sample056: 100%|██████████| 50/50 [00:01<00:00, 27.52it/s]\n",
      "current directory of images: Sample057: 100%|██████████| 50/50 [00:01<00:00, 28.95it/s]\n",
      "current directory of images: Sample058: 100%|██████████| 50/50 [00:01<00:00, 29.34it/s]\n",
      "current directory of images: Sample059: 100%|██████████| 50/50 [00:01<00:00, 29.36it/s]\n",
      "current directory of images: Sample060: 100%|██████████| 50/50 [00:01<00:00, 29.10it/s]\n",
      "current directory of images: Sample061: 100%|██████████| 50/50 [00:01<00:00, 28.27it/s]\n",
      "current directory of images: Sample062: 100%|██████████| 50/50 [00:01<00:00, 28.58it/s]\n",
      "current directory of images: sample001: 100%|██████████| 5/5 [00:00<00:00, 28.65it/s]\n",
      "current directory of images: sample002:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data: \"OCRANN_validation\"\n",
      "Loading 310 images\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current directory of images: sample002: 100%|██████████| 5/5 [00:00<00:00, 26.46it/s]\n",
      "current directory of images: sample003: 100%|██████████| 5/5 [00:00<00:00, 27.04it/s]\n",
      "current directory of images: sample004: 100%|██████████| 5/5 [00:00<00:00, 27.56it/s]\n",
      "current directory of images: sample005: 100%|██████████| 5/5 [00:00<00:00, 28.81it/s]\n",
      "current directory of images: sample006: 100%|██████████| 5/5 [00:00<00:00, 28.24it/s]\n",
      "current directory of images: sample007: 100%|██████████| 5/5 [00:00<00:00, 28.56it/s]\n",
      "current directory of images: sample008: 100%|██████████| 5/5 [00:00<00:00, 28.86it/s]\n",
      "current directory of images: sample009: 100%|██████████| 5/5 [00:00<00:00, 29.69it/s]\n",
      "current directory of images: sample010: 100%|██████████| 5/5 [00:00<00:00, 30.03it/s]\n",
      "current directory of images: sample011: 100%|██████████| 5/5 [00:00<00:00, 28.79it/s]\n",
      "current directory of images: sample012: 100%|██████████| 5/5 [00:00<00:00, 27.52it/s]\n",
      "current directory of images: sample013: 100%|██████████| 5/5 [00:00<00:00, 29.37it/s]\n",
      "current directory of images: sample014: 100%|██████████| 5/5 [00:00<00:00, 28.89it/s]\n",
      "current directory of images: sample015: 100%|██████████| 5/5 [00:00<00:00, 29.94it/s]\n",
      "current directory of images: Sample016: 100%|██████████| 5/5 [00:00<00:00, 28.96it/s]\n",
      "current directory of images: Sample017: 100%|██████████| 5/5 [00:00<00:00, 28.54it/s]\n",
      "current directory of images: Sample018: 100%|██████████| 5/5 [00:00<00:00, 28.65it/s]\n",
      "current directory of images: Sample019: 100%|██████████| 5/5 [00:00<00:00, 29.13it/s]\n",
      "current directory of images: Sample020: 100%|██████████| 5/5 [00:00<00:00, 29.83it/s]\n",
      "current directory of images: Sample021: 100%|██████████| 5/5 [00:00<00:00, 28.46it/s]\n",
      "current directory of images: Sample022: 100%|██████████| 5/5 [00:00<00:00, 29.21it/s]\n",
      "current directory of images: Sample023: 100%|██████████| 5/5 [00:00<00:00, 28.96it/s]\n",
      "current directory of images: Sample024: 100%|██████████| 5/5 [00:00<00:00, 28.48it/s]\n",
      "current directory of images: Sample025: 100%|██████████| 5/5 [00:00<00:00, 29.36it/s]\n",
      "current directory of images: Sample026: 100%|██████████| 5/5 [00:00<00:00, 28.33it/s]\n",
      "current directory of images: Sample027: 100%|██████████| 5/5 [00:00<00:00, 28.57it/s]\n",
      "current directory of images: Sample028: 100%|██████████| 5/5 [00:00<00:00, 28.39it/s]\n",
      "current directory of images: Sample029: 100%|██████████| 5/5 [00:00<00:00, 28.64it/s]\n",
      "current directory of images: Sample030: 100%|██████████| 5/5 [00:00<00:00, 29.15it/s]\n",
      "current directory of images: Sample031: 100%|██████████| 5/5 [00:00<00:00, 29.98it/s]\n",
      "current directory of images: Sample032: 100%|██████████| 5/5 [00:00<00:00, 29.29it/s]\n",
      "current directory of images: Sample033: 100%|██████████| 5/5 [00:00<00:00, 30.08it/s]\n",
      "current directory of images: Sample034: 100%|██████████| 5/5 [00:00<00:00, 28.36it/s]\n",
      "current directory of images: Sample035: 100%|██████████| 5/5 [00:00<00:00, 29.25it/s]\n",
      "current directory of images: Sample036: 100%|██████████| 5/5 [00:00<00:00, 24.50it/s]\n",
      "current directory of images: Sample037: 100%|██████████| 5/5 [00:00<00:00, 27.69it/s]\n",
      "current directory of images: Sample038: 100%|██████████| 5/5 [00:00<00:00, 27.75it/s]\n",
      "current directory of images: Sample039: 100%|██████████| 5/5 [00:00<00:00, 28.05it/s]\n",
      "current directory of images: Sample040: 100%|██████████| 5/5 [00:00<00:00, 25.52it/s]\n",
      "current directory of images: Sample041: 100%|██████████| 5/5 [00:00<00:00, 19.14it/s]\n",
      "current directory of images: Sample042: 100%|██████████| 5/5 [00:00<00:00, 24.06it/s]\n",
      "current directory of images: Sample043: 100%|██████████| 5/5 [00:00<00:00,  6.34it/s]\n",
      "current directory of images: Sample044: 100%|██████████| 5/5 [00:00<00:00, 16.37it/s]\n",
      "current directory of images: Sample045: 100%|██████████| 5/5 [00:00<00:00, 22.68it/s]\n",
      "current directory of images: Sample046: 100%|██████████| 5/5 [00:00<00:00, 22.90it/s]\n",
      "current directory of images: Sample047: 100%|██████████| 5/5 [00:00<00:00, 23.78it/s]\n",
      "current directory of images: Sample048: 100%|██████████| 5/5 [00:00<00:00, 23.31it/s]\n",
      "current directory of images: Sample049: 100%|██████████| 5/5 [00:00<00:00, 24.41it/s]\n",
      "current directory of images: Sample050: 100%|██████████| 5/5 [00:00<00:00, 27.79it/s]\n",
      "current directory of images: Sample051: 100%|██████████| 5/5 [00:00<00:00, 23.49it/s]\n",
      "current directory of images: Sample052: 100%|██████████| 5/5 [00:00<00:00, 25.76it/s]\n",
      "current directory of images: Sample053: 100%|██████████| 5/5 [00:00<00:00, 25.50it/s]\n",
      "current directory of images: Sample054: 100%|██████████| 5/5 [00:00<00:00, 25.82it/s]\n",
      "current directory of images: Sample055: 100%|██████████| 5/5 [00:00<00:00, 22.95it/s]\n",
      "current directory of images: Sample056: 100%|██████████| 5/5 [00:00<00:00, 26.11it/s]\n",
      "current directory of images: Sample057: 100%|██████████| 5/5 [00:00<00:00, 26.63it/s]\n",
      "current directory of images: Sample058: 100%|██████████| 5/5 [00:00<00:00, 26.60it/s]\n",
      "current directory of images: Sample059: 100%|██████████| 5/5 [00:00<00:00, 28.03it/s]\n",
      "current directory of images: Sample060: 100%|██████████| 5/5 [00:00<00:00, 23.74it/s]\n",
      "current directory of images: Sample061: 100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n",
      "current directory of images: Sample062: 100%|██████████| 5/5 [00:00<00:00, 25.51it/s]\n"
     ]
    }
   ],
   "source": [
    "train = load_data('OCRANN_train')  # AV_\n",
    "validation = load_data('OCRANN_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3100/3100 [==============================] - 148s - loss: 3.8984 - acc: 0.0761   \n",
      "\n",
      "\n",
      "310/310 [==============================] - 8s     \n",
      "loss: 3.5014\n",
      "accuracy: 0.171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = neural_network(train, validation, activations=('relu', 'relu', 'softmax'), nb_epoch=1, batch_size=30, optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1180/3100 [==========>...................] - ETA: 92s - loss: 3.0067 - acc: 0.2449"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-8751e25803a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/valerio/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/valerio/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/valerio/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/valerio/anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/valerio/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/valerio/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/valerio/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/valerio/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/valerio/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=train[0], y=train[1], nb_epoch=4, batch_size=10)\n",
    "print('\\n')\n",
    "loss, accuracy = model.evaluate(x=validation[0], y=validation[1], batch_size=1, verbose=1)\n",
    "print('loss: ' + str(round(loss, 4)))\n",
    "print('accuracy: ' + str(round(accuracy, 4)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
